{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28b88b4",
   "metadata": {},
   "source": [
    "# Population Estimates: Compute confidence levels for all parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cef5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a1f5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "%run inference-functions.ipynb import load_data, get_bounds, assign_cbgs, visualize_tile_predvOSM, assign_cbgs_by_coverage\n",
    "%run ADU_permit_matching-polygon-pipeline.ipynb import load_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44031031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "OAK_FP = '/oak/stanford/groups/deho/building_compliance/'\n",
    "OUTPUT_FP = os.path.join(OAK_FP, 'outputs', 'Population-Estimates', 'outputs')\n",
    "PERMIT_INPUT_FP = os.path.join(OAK_FP, 'outputs', 'Permit-Matching', 'inputs')\n",
    "\n",
    "BUILD_FP = os.path.join(OAK_FP, 'outputs', 'cbg-inference-{}', 'inference_building_processed')\n",
    "OSM_FP = os.path.join(OAK_FP, 'outputs', 'cbg-inference-2020', 'osm_building_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e7d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "# * Percentage of samples in each income strata to process\n",
    "percentage_of_samples = 1\n",
    "\n",
    "# * Divide compute ----- MODIFY AGENT HERE (N Nathan, A Andrea) ---------\n",
    "agent = 'N'\n",
    "\n",
    "# Note: These parameters are relevant for how OSM footprints are used\n",
    "# to identify the main building and to decide whether to snap to OSM small building \n",
    "# footprints. \n",
    "# The limit_2016_inferences parameter determines whether OSM footprints are used \n",
    "# symmetrically for 2020 and 2016. If True, we only include OSM footprints for 2016\n",
    "# if these have been partially discovered by model inferences. If False, we include\n",
    "# any OSM small building for the 2016 footprints (as done for 2020).\n",
    "\n",
    "model_params = {'area_threshold_main': 30, 'area_threshold_small': 20,\n",
    "                'flatten_threshold': 0.85, 'main_expansion_type': 'raw_polygons', \n",
    "                'main_polygon_definition': 'OSM', 'negative_buffer': 0.5, 'simplify_tolerance': 0,\n",
    "                'limit_2016_inferences': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e3812",
   "metadata": {},
   "source": [
    "# 1. Compute confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f46427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcel_confidence(sj_parcels_res, sj_parcel_permit, parcel_apn, model_params):\n",
    "    # Collect parcel data\n",
    "    inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel, permits_parcel = parcel_level_data(parcel_apn, sj_parcels_res, sj_parcel_permit)\n",
    "    parcel_bounds = sj_parcels_res[sj_parcels_res['APN'] == parcel_apn]\n",
    "\n",
    "    # Prepare data\n",
    "    inferred_buildings_parcel = {'2016': inferred_buildings_2016_parcel,\n",
    "                                 '2020': inferred_buildings_2020_parcel}\n",
    "    \n",
    "    osm_buildings_parcel = {'2016': osm_buildings_parcel,\n",
    "                            '2020': osm_buildings_parcel}\n",
    "\n",
    "    if inferred_buildings_2016_parcel is None:\n",
    "        inferred_buildings_2016_parcel = pd.DataFrame(columns=['GEOID', 'area', 'small', 'large', 'geometry', 'iou'])\n",
    "    inferred_buildings_2016_parcel = inferred_buildings_2016_parcel[inferred_buildings_2016_parcel['small'] == 1]\n",
    "    inferred_buildings_2016_parcel = inferred_buildings_2016_parcel.reset_index(drop=True)\n",
    "\n",
    "    # Incorporate OSM data\n",
    "    parcel_buildings, _ = process_parcel_buildings(\n",
    "        inferred_buildings_parcel, osm_buildings_parcel, parcel_bounds, model_params)\n",
    "    \n",
    "    for year in ['2016', '2020']:\n",
    "        if parcel_buildings[year] is None: # means there is no building (not even main building?)\n",
    "            parcel_buildings[year] = pd.DataFrame(columns=['main_building_flag', 'OSM_flag', \n",
    "                                                           'build_confidence', 'geometry', 'area'])\n",
    "            continue\n",
    "            \n",
    "        small_buildings = parcel_buildings[year].copy()\n",
    "        parcel_buildings[year] = small_buildings[small_buildings['main_building_flag'] == False].reset_index(drop=True)\n",
    "\n",
    "    if parcel_buildings['2020'].empty:\n",
    "        return 1, parcel_buildings\n",
    "    elif inferred_buildings_2016_parcel.empty and not parcel_buildings['2020'].empty:\n",
    "        return 3, parcel_buildings\n",
    "    elif len(inferred_buildings_2016_parcel) == 1 and len(parcel_buildings['2020']) == 1: # do we need to care about intersection?\n",
    "        return 2, parcel_buildings\n",
    "    elif len(inferred_buildings_2016_parcel) > len(parcel_buildings['2020']):\n",
    "        return 2, parcel_buildings\n",
    "    else:\n",
    "        building_no_pair_found = False\n",
    "        len_2020 = len(parcel_buildings['2020'])\n",
    "        counter = 0\n",
    "        while not building_no_pair_found and counter < len_2020:\n",
    "            building_2020 = parcel_buildings['2020'].loc[counter]\n",
    "            \n",
    "            # try to find a pair in 2016\n",
    "            found_idx = None\n",
    "            for idx, building_2016 in inferred_buildings_2016_parcel.iterrows():\n",
    "                # IOU\n",
    "                if building_2020['geometry'].intersection(building_2016['geometry']).area/building_2020['geometry'].union(building_2016['geometry']).area > 0:\n",
    "                    found_idx = idx\n",
    "                    break\n",
    "            \n",
    "            if found_idx is None:\n",
    "                building_no_pair_found = True\n",
    "#             else:\n",
    "#                 # take the 2016 pair found away from the table\n",
    "#                 # EDIT: i actually don't think this is necessary, esp for buildings that are so close to each other\n",
    "            counter += 1\n",
    "    \n",
    "        if building_no_pair_found:\n",
    "            # take the 2020 entry where no building was found, output that confidence\n",
    "            return 3, parcel_buildings\n",
    "        else:\n",
    "            return 2, parcel_buildings\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29270a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    # * Residential parcels (assigned to CBGs)\n",
    "    sj_parcels_res = gpd.read_file(os.path.join(OUTPUT_FP, 'sj-parcels-res-cbgs'))\n",
    "    assert sj_parcels_res.duplicated('APN').sum() == 0\n",
    "\n",
    "    # * Census block groups\n",
    "    cbg_income_2016_SJ = gpd.read_file(os.path.join(OUTPUT_FP, 'Strata', 'cbg-income-strata'))\n",
    "\n",
    "    # * Permits\n",
    "    sj_parcel_permit = pd.read_csv(os.path.join(PERMIT_INPUT_FP, '..', 'outputs', 'parcel_permit_found.csv'))\n",
    "    sj_permit_noparcel = pd.read_csv(os.path.join(PERMIT_INPUT_FP, '..', 'outputs', 'parcel_permit_notfound.csv'))\n",
    "    sj_parcel_permit['geometry_parcel'] = gpd.GeoSeries.from_wkt(sj_parcel_permit['geometry_parcel'])\n",
    "    sj_parcel_permit['geometry_permit'] = gpd.GeoSeries.from_wkt(sj_parcel_permit['geometry_permit'])\n",
    "    \n",
    "    # Add income strata information to parcel data\n",
    "    sj_parcels_res = pd.merge(\n",
    "        sj_parcels_res, cbg_income_2016_SJ[['GEOID', 'strata_inc']], \n",
    "        how='left', validate='many_to_one')\n",
    "    \n",
    "    # Divide compute (split up the income strata)\n",
    "    unique_strata = sj_parcels_res['strata_inc'].unique()\n",
    "\n",
    "    # Find a seed that balances the number of APNs \n",
    "    np.random.seed(44)\n",
    "    a1_strata = np.random.choice(unique_strata, size=len(unique_strata)//2, replace=False)\n",
    "\n",
    "    sj_parcels_res['agent'] = sj_parcels_res['strata_inc'].apply(\n",
    "        lambda strata_inc: 'A' if strata_inc in a1_strata else 'N')\n",
    "    \n",
    "    # Drop parcels for other agent\n",
    "    sj_parcels_res = sj_parcels_res.loc[sj_parcels_res['agent'] == agent]\n",
    "    \n",
    "    # Set up output files\n",
    "    parcel_output = os.path.join(OUTPUT_FP, 'Confidences_construction', agent, 'parcel-confidence.csv')\n",
    "    building_output = os.path.join(OUTPUT_FP, 'Confidences_construction', agent, 'building-confidence-{}')\n",
    "\n",
    "    if os.path.exists(parcel_output):\n",
    "        parcel_conf_df = pd.read_csv(parcel_output)\n",
    "        buildings_gpd = {'2016': gpd.read_file(building_output.format('2016')), \n",
    "                     '2020': gpd.read_file(building_output.format('2020'))}\n",
    "\n",
    "        reviewed_parcels = parcel_conf_df['APN'].unique()\n",
    "        reviewed_istrata = parcel_conf_df['strata_inc'].unique()\n",
    "\n",
    "        print('[INFO] Number of reviewed income strata: {}'.format(len(reviewed_istrata)))\n",
    "        print('[INFO] Number of reviewed parcels: {}'.format(len(reviewed_parcels)))\n",
    "\n",
    "    else:\n",
    "        os.makedirs(os.path.dirname(parcel_output))\n",
    "\n",
    "        parcel_conf_df = pd.DataFrame()\n",
    "        buildings_gpd = {'2016': gpd.GeoDataFrame(geometry=[]), '2020': gpd.GeoDataFrame(geometry=[])}\n",
    "        reviewed_parcels = []\n",
    "    # Compute confidence for each parcel, order by income strata\n",
    "    for strata_inc in tqdm(sj_parcels_res['strata_inc'].unique()):\n",
    "        parcels_to_review = sj_parcels_res.loc[sj_parcels_res['strata_inc'] == strata_inc]['APN'].unique()\n",
    "\n",
    "        # Sample parcels\n",
    "        np.random.seed(42)\n",
    "        strata_inc_N = len(parcels_to_review)\n",
    "        parcels_to_review = np.random.choice(\n",
    "            parcels_to_review, size=int(strata_inc_N * percentage_of_samples), replace=False)\n",
    "        for i, parcel_apn in enumerate(parcels_to_review):\n",
    "            if parcel_apn in reviewed_parcels:\n",
    "                continue\n",
    "\n",
    "            # Compute confidence\n",
    "            parcel_conf, parcel_build = parcel_confidence(\n",
    "                sj_parcels_res, sj_parcel_permit, parcel_apn, model_params)\n",
    "\n",
    "            # Get geoid\n",
    "            parcel_geoid = sj_parcels_res.loc[sj_parcels_res['APN'] == parcel_apn].iloc[0]['GEOID']\n",
    "\n",
    "            # Append\n",
    "            parcel_conf_df = pd.concat([parcel_conf_df, pd.DataFrame.from_dict(\n",
    "                {'APN': [parcel_apn], 'GEOID': [parcel_geoid],\n",
    "                 'strata_inc': [strata_inc], 'confidence': [parcel_conf]})])\n",
    "\n",
    "            for year in ['2016', '2020']:\n",
    "                if parcel_build[year] is not None:\n",
    "                    parcel_build[year]['APN'] = parcel_apn\n",
    "                    buildings_gpd[year] = pd.concat([buildings_gpd[year], parcel_build[year]])\n",
    "\n",
    "            if i > 0 and (i % 50 == 0 or i == len(parcels_to_review)):\n",
    "                parcel_conf_df.to_csv(parcel_output, index=False)\n",
    "                for year in ['2016', '2020']:\n",
    "                    buildings_gpd[year].to_file(building_output.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940a38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of reviewed income strata: 2\n",
      "[INFO] Number of reviewed parcels: 9540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24be159",
   "metadata": {},
   "source": [
    "# 2. Finalize\n",
    "Concatenate both parcel confidence datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d750310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of reviewed income strata: 51\n",
      "[INFO] Number of reviewed parcels: 162685\n"
     ]
    }
   ],
   "source": [
    "# Load parceland CBG data\n",
    "cbg_income_2016_SJ = gpd.read_file(os.path.join(OUTPUT_FP, 'Strata', 'cbg-income-strata'))\n",
    "sj_parcels_res = gpd.read_file(os.path.join(OUTPUT_FP, 'sj-parcels-res-cbgs'))\n",
    "\n",
    "# Load separate parcel confidence data frames\n",
    "parcel_conf_df = pd.DataFrame()\n",
    "for agent in ['A', 'N']:\n",
    "    parcel_output = os.path.join(OUTPUT_FP, 'Confidences_construction', agent, 'parcel-confidence.csv')\n",
    "    \n",
    "    parcel_conf_df = pd.concat([parcel_conf_df, pd.read_csv(parcel_output, dtype={'GEOID': 'str'})])\n",
    "    \n",
    "reviewed_parcels = parcel_conf_df['APN'].unique()\n",
    "reviewed_istrata = parcel_conf_df['strata_inc'].unique()\n",
    "\n",
    "print('[INFO] Number of reviewed income strata: {}'.format(len(reviewed_istrata)))\n",
    "print('[INFO] Number of reviewed parcels: {}'.format(len(reviewed_parcels)))\n",
    "\n",
    "# Drop duplicates\n",
    "parcel_conf_df.drop_duplicates(subset=['APN', 'confidence'], inplace=True)\n",
    "\n",
    "parcel_conf_df = parcel_conf_df[['APN', 'confidence']]\n",
    "\n",
    "# Re-do GEOID (because it incorrectly saves as int)\n",
    "parcel_conf_df = pd.merge(\n",
    "    parcel_conf_df, sj_parcels_res[['APN', 'GEOID']], how='left', validate='one_to_one')\n",
    "\n",
    "# Re-do strata_income\n",
    "parcel_conf_df = pd.merge(\n",
    "    parcel_conf_df, cbg_income_2016_SJ[['GEOID', 'strata_inc']], how='left', \n",
    "    validate='many_to_one')\n",
    "\n",
    "# Save\n",
    "parcel_conf_df.to_csv(os.path.join(OUTPUT_FP, 'Confidences_construction', 'parcel-confidence.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6027172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162685 entries, 0 to 162684\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   APN         162685 non-null  object \n",
      " 1   confidence  38886 non-null   float64\n",
      " 2   GEOID       159883 non-null  object \n",
      " 3   strata_inc  159883 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "parcel_conf_df = pd.read_csv(os.path.join(OUTPUT_FP, 'Confidences_construction', 'parcel-confidence.csv'), \n",
    "                             dtype={'GEOID': str})\n",
    "parcel_conf_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5bf519",
   "metadata": {},
   "source": [
    "Building confidences: issue that different column names were created (due to GPD limits on col name length) so buildings were not concatenated correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e2ce301",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_gpd = {'2016': gpd.GeoDataFrame(),  '2020': gpd.GeoDataFrame()}\n",
    "\n",
    "for agent in ['A', 'N']:\n",
    "    building_output = os.path.join(OUTPUT_FP, 'Confidences_construction', agent, 'building-confidence-{}')\n",
    "\n",
    "    for year in ['2016', '2020']:\n",
    "        buildings_gpd[year] = pd.concat(\n",
    "            [buildings_gpd[year], gpd.read_file(building_output.format(year))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86250175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "for year in ['2016', '2020']:\n",
    "    buildings_gpd[year].to_file(os.path.join(\n",
    "        OUTPUT_FP, 'Confidences_construction', 'building-confidence-{}'.format(year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfed44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_gpd['2020']['build_conf'] = buildings_gpd['2020']['build_conf'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b8fa38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_build</th>\n",
       "      <th>OSM_flag</th>\n",
       "      <th>build_conf</th>\n",
       "      <th>area</th>\n",
       "      <th>APN</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8265858678962559</td>\n",
       "      <td>304.303273</td>\n",
       "      <td>61248010</td>\n",
       "      <td>POLYGON ((-121.80168 37.36919, -121.80168 37.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7925487726368186</td>\n",
       "      <td>139.626724</td>\n",
       "      <td>67847079</td>\n",
       "      <td>POLYGON ((-121.78191 37.24780, -121.78191 37.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.870618975395968</td>\n",
       "      <td>214.732877</td>\n",
       "      <td>69525043</td>\n",
       "      <td>POLYGON ((-121.83270 37.23293, -121.83270 37.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.972158</td>\n",
       "      <td>69525043</td>\n",
       "      <td>POLYGON ((-121.83257 37.23306, -121.83257 37.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7890311011722161</td>\n",
       "      <td>173.054128</td>\n",
       "      <td>61259042</td>\n",
       "      <td>POLYGON ((-121.79939 37.35804, -121.79939 37.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  main_build OSM_flag          build_conf        area       APN  \\\n",
       "0          1        0  0.8265858678962559  304.303273  61248010   \n",
       "1          1        0  0.7925487726368186  139.626724  67847079   \n",
       "2          1        0   0.870618975395968  214.732877  69525043   \n",
       "3          0        1                   0   24.972158  69525043   \n",
       "4          1        0  0.7890311011722161  173.054128  61259042   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-121.80168 37.36919, -121.80168 37.3...  \n",
       "1  POLYGON ((-121.78191 37.24780, -121.78191 37.2...  \n",
       "2  POLYGON ((-121.83270 37.23293, -121.83270 37.2...  \n",
       "3  POLYGON ((-121.83257 37.23306, -121.83257 37.2...  \n",
       "4  POLYGON ((-121.79939 37.35804, -121.79939 37.3...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildings_gpd['2020'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e86493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_output = os.path.join(OUTPUT_FP, 'Confidences_construction', 'N', 'building-confidence-{}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
