{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5af55ad",
   "metadata": {},
   "source": [
    "# Identify permitted and potentially unpermitted attached and detached units in San Jose (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc420f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae725b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "OAK_FP = '/oak/stanford/groups/deho/building_compliance/'\n",
    "INPUT_FP = os.path.join(OAK_FP, 'outputs', 'Permit-Matching')\n",
    "SJ_RES_PARCELS_FP = os.path.join(INPUT_FP, 'inputs', 'san_jose_parcels_res.geojson')\n",
    "ZONING_FP = os.path.join(OAK_FP, 'san_jose_suppl', 'san_jose_Zoning_Districts.geojson')\n",
    "BUILD_FP = os.path.join(OAK_FP, 'outputs', 'cbg-inference-{}', 'inference_building_processed')\n",
    "OSM_FP = os.path.join(OAK_FP, 'outputs', 'cbg-inference-2020', 'osm_building_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd200028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# * Residential parcels\n",
    "sj_parcels_res = gpd.read_file(SJ_RES_PARCELS_FP)\n",
    "sj_parcels_res = sj_parcels_res[sj_parcels_res['APN'].notna()]\n",
    "\n",
    "# * Building permits\n",
    "bldg_active = gpd.read_file(os.path.join(INPUT_FP, 'inputs', 'permits', 'bldg_active.geojson'))\n",
    "bldg_recent = gpd.read_file(os.path.join(INPUT_FP, 'inputs','permits', 'bldg_recent.geojson'))\n",
    "bldg_expired = gpd.read_file(os.path.join(INPUT_FP, 'inputs', 'permits', 'bldg_expired.geojson'))\n",
    "\n",
    "# * Zoning\n",
    "sj_zoning = gpd.read_file(ZONING_FP)\n",
    "sj_residential = sj_zoning[(sj_zoning['ZONING'].str.contains('R-1')) | (sj_zoning['ZONING'].str.contains('R-2')) |\\\n",
    "         ((sj_zoning['ZONING'].str.contains('R-M')) & (sj_zoning['ZONING'] != 'R-MH'))]\n",
    "\n",
    "# * parcel+permit\n",
    "sj_parcel_permit = pd.read_csv(os.path.join(INPUT_FP, 'outputs', 'parcel_permit_found.csv'))\n",
    "sj_permit_noparcel = pd.read_csv(os.path.join(INPUT_FP, 'outputs', 'parcel_permit_notfound.csv'))\n",
    "sj_parcel_permit['geometry_parcel'] = gpd.GeoSeries.from_wkt(sj_parcel_permit['geometry_parcel'])\n",
    "sj_parcel_permit['geometry_permit'] = gpd.GeoSeries.from_wkt(sj_parcel_permit['geometry_permit'])\n",
    "sj_permit_noparcel['geometry'] = gpd.GeoSeries.from_wkt(sj_permit_noparcel['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d495de",
   "metadata": {},
   "source": [
    "Handle active permits differently than expired permits\n",
    "- Expired permits barely report dwelling units and square footage\n",
    "- Should we filter really finely like we do for active permits, or filter for just work description as we do for expired permits to catch ALL the construction permits we can find? I worry that some of the buildings we infer will be under non-SFR permits\n",
    "\n",
    "Keep this block of code in case we want to filter more specifically for possible dwelling units, but we will work with the more relaxed conditions to get more possible permits to compare to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9078811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter permits\n",
    "cols = list(bldg_active.columns) + ['permit_status']\n",
    "permits = gpd.GeoDataFrame(columns=cols)\n",
    "for i, status in zip([bldg_active, bldg_recent, bldg_expired], ['active', 'recent', 'expired']):\n",
    "    i['permit_status'] = status\n",
    "    permits = pd.concat([permits, i[i['WORKDESC'].isin(['New Construction', 'Additions/Alterations'])]])\n",
    "permits = permits.reset_index(drop=True)\n",
    "\n",
    "permits.crs = \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a041a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e679cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_parcel(parcel_apn):\n",
    "    # Obtain parcel-level data\n",
    "    parcel_inputs = parcel_level_data(\n",
    "      parcel_apn, sj_parcels_res, sj_parcel_permit)\n",
    "    inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel, permits_parcel = parcel_inputs\n",
    "\n",
    "    # Incorporate OSM data\n",
    "    parcel_buildings = process_OSM_data(\n",
    "      inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel)\n",
    "\n",
    "    # Incorporate permit data\n",
    "    parcel_buildings = process_permit_data(parcel_apn, permits_parcel, parcel_buildings)\n",
    "\n",
    "    return parcel_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39cc119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcel_level_data(parcel_apn, sj_parcels_res, sj_parcel_permit):\n",
    "    parcel_bounds = sj_parcels_res[sj_parcels_res['APN'] == parcel_apn]\n",
    "\n",
    "    # clip inferred buildings and osm buildings\n",
    "    # i don't think clip is a good idea since it truncates the inferences according to the mask\n",
    "    # inferred_buildings_2020_parcel = gpd.clip(building_inference_2020, parcel_bounds)\n",
    "\n",
    "    # def mask_buildings(df, parcel_bounds):\n",
    "    #   df_out = df.sjoin(parcel_bounds[['geometry','geom']])\n",
    "    #   # print(df_out)\n",
    "    #   df_out['iou'] = df_out['geometry'].intersection(df_out['geom']).area/df_out['geom'].area\n",
    "    #   df_out = df_out[df_out['iou'] > 0.7]\n",
    "    #   return df_out\n",
    "\n",
    "    def mask_buildings1(parcel_bounds, fp):\n",
    "        df_out = gpd.read_file(fp, mask=parcel_bounds)\n",
    "        df_out['iou'] = df_out['geometry'].intersection(parcel_bounds).area/df_out['geometry'].area\n",
    "        df_out = df_out[df_out['iou'] > 0.7]\n",
    "        if df_out.empty:\n",
    "            return None\n",
    "        else:\n",
    "            return df_out\n",
    "\n",
    "    inferred_buildings_2020_parcel = mask_buildings1(parcel_bounds['geometry'].values[0], BUILD_FP.format('2020'))\n",
    "    inferred_buildings_2016_parcel = mask_buildings1(parcel_bounds['geometry'].values[0], BUILD_FP.format('2016'))\n",
    "    osm_buildings_parcel = mask_buildings1(parcel_bounds['geometry'].values[0], OSM_FP)\n",
    "\n",
    "    permits_parcel = sj_parcel_permit[sj_parcel_permit['APN_parcel'] == parcel_apn]\n",
    "    if permits_parcel.empty:\n",
    "        permits_parcels = None\n",
    "\n",
    "    return inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel, permits_parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "214e90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_ATTACHED_SIZE = 40\n",
    "MIN_ATTACHED_SIZE_2020_2016_DIFF = 40\n",
    "MIN_ATTACHED_SIZE_OSM_2016_DIFF = 40\n",
    "\n",
    "def process_OSM_data(inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel):\n",
    "    # Returns a gpd.GeoDataFrame with the following columns:\n",
    "    #   - GEOID, area, small, large\n",
    "    #   - flags: OSM_flag, expansion_OSM_flag, main_building_flag, expansion_2016_flat\n",
    "    #   - building geometry\n",
    "    gpd_cols = ['main_building_flag', 'OSM_flag', 'expansion_OSM_flag', 'expansion_2016_flag', 'geometry']\n",
    "    parcel_buildings = gpd.GeoDataFrame(geometry=[], columns=gpd_cols)\n",
    "    \n",
    "    # Drop OSM index_left column\n",
    "    if osm_buildings_parcel is not None and 'index_left' in osm_buildings_parcel.columns:\n",
    "        osm_buildings_parcel.drop('index_left', axis=1, inplace=True)\n",
    "        \n",
    "    # Identify main 2016 building to check for expansions in cases below\n",
    "    inference_main_build_geom_2016 = None\n",
    "    if inferred_buildings_2016_parcel is not None:\n",
    "        # Identify 2016 main building\n",
    "        inferred_buildings_2016_parcel = inferred_buildings_2016_parcel.sort_values(\n",
    "            'area', ascending=False)\n",
    "        inference_main_build_2016 = inferred_buildings_2016_parcel.iloc[0]\n",
    "        inference_main_build_geom_2016 = inference_main_build_2016['geometry']\n",
    "\n",
    "        \n",
    "    # Case 1: No inference nor OSM data ----------------- \n",
    "    if inferred_buildings_2020_parcel is None and osm_buildings_parcel is None:\n",
    "        return parcel_buildings\n",
    "\n",
    "    \n",
    "    # Case 2: No inference but OSM data ----------------- \n",
    "    # We fully rely on OSM data\n",
    "    if inferred_buildings_2020_parcel is None and osm_buildings_parcel is not None:\n",
    "        parcel_buildings = osm_buildings_parcel.copy()\n",
    "        parcel_buildings = parcel_buildings.sort_values('area', ascending=False)\n",
    "        parcel_buildings['main_building_flag'] = parcel_buildings.apply(\n",
    "            lambda row: True if row.name == 0 else False, axis=1)\n",
    "        parcel_buildings['OSM_flag'] = True\n",
    "        parcel_buildings['expansion_OSM_flag'] = False\n",
    "        parcel_buildings['expansion_2016_flag'] = None\n",
    "        \n",
    "        # Check for OSM expansion vs 2016\n",
    "        if inference_main_build_geom_2016 is not None: \n",
    "            parcel_buildings['expansion_2016_flag'] = False\n",
    "            \n",
    "            # Get OSM main building\n",
    "            osm_main_build = osm_buildings_parcel.sort_values('area', ascending=False).iloc[[0]]\n",
    "            osm_main_build_geom = osm_main_build['geometry'].iloc[0]\n",
    "            \n",
    "            union_main_build = osm_main_build_geom.union(inference_main_build_geom_2016)\n",
    "            diff_OSM_16 = compute_largest_protruding_poly(\n",
    "                union_main_build, inference_main_build_geom_2016)\n",
    "            \n",
    "            if diff_OSM_16['area'] > MIN_ATTACHED_SIZE_OSM_2016_DIFF:\n",
    "                parcel_buildings['expansion_2016_flag'] = parcel_buildings.apply(\n",
    "                lambda row: True if row.name == 0 else False, axis=1)\n",
    "        return parcel_buildings[gpd_cols]\n",
    "    \n",
    "    \n",
    "    # Case 3: Inference and no OSM data ----------------- \n",
    "    if osm_buildings_parcel is None:\n",
    "\n",
    "        # i. Identify main building in 2020 data as the largest polygon\n",
    "        inferred_buildings_2020_parcel = inferred_buildings_2020_parcel.sort_values(\n",
    "            'area', ascending=False)\n",
    "        inference_main_build = inferred_buildings_2020_parcel.iloc[[0]]\n",
    "        inference_main_build_geom = inference_main_build['geometry'].iloc[0]\n",
    "        expansion_2016_flag = None\n",
    "\n",
    "        parcel_buildings = inference_main_build.copy()\n",
    "\n",
    "        # ii. Compare to 2016 footprint\n",
    "        if inference_main_build_geom_2016 is not None:\n",
    "            expansion_2016_flag = False\n",
    "            union_main_build = inference_main_build_geom.union(inference_main_build_geom_2016)\n",
    "            diff_20_16 = compute_largest_protruding_poly(union_main_build, inference_main_build_geom_2016)\n",
    "\n",
    "            if diff_20_16['area'] > MIN_ATTACHED_SIZE_2020_2016_DIFF:\n",
    "                parcel_buildings = inference_main_build_2016.copy()\n",
    "                expansion_2016_flag = True\n",
    "\n",
    "        parcel_buildings['expansion_2016_flag'] = expansion_2016_flag\n",
    "        parcel_buildings['expansion_OSM_flag'] = None\n",
    "        parcel_buildings['main_building_flag'] = True\n",
    "        parcel_buildings['OSM_flag'] = False\n",
    "        parcel_buildings = parcel_buildings[gpd_cols]\n",
    "\n",
    "        # iii. Add inferred small buildings \n",
    "        inferred_small = inferred_buildings_2020_parcel.iloc[1:].copy()\n",
    "        inferred_small['expansion_OSM_flag'] = False\n",
    "        inferred_small['expansion_2016_flag'] = False\n",
    "        inferred_small['OSM_flag'] = False\n",
    "        inferred_small['main_building_flag'] = False\n",
    "        parcel_buildings = pd.concat([parcel_buildings, inferred_small[gpd_cols]])\n",
    "\n",
    "        return parcel_buildings[gpd_cols]\n",
    "\n",
    "    # Case 4: Inference and OSM data -----------------   \n",
    "    parcel_buildings = gpd.GeoDataFrame(geometry=[])\n",
    "\n",
    "    # i. Identify main building(s) in OSM and inferences\n",
    "    osm_main_build = osm_buildings_parcel.sort_values('area', ascending=False).iloc[[0]]\n",
    "    osm_main_build_geom = osm_main_build['geometry'].iloc[0]\n",
    "\n",
    "    inference_main_build = inferred_buildings_2020_parcel.sjoin(\n",
    "        osm_main_build, how='left', predicate='intersects')\n",
    "    inference_main_build = inference_main_build.loc[~inference_main_build['index_right'].isna()]\n",
    "    inference_main_build_geom = inference_main_build.geometry.unary_union\n",
    "    inference_main_build.drop('index_right', axis=1, inplace=True)\n",
    "    \n",
    "    expansion_OSM_flag = False\n",
    "    osm_flag = True\n",
    "    # If there is no overlap between model inferences and OSM, we use OSM main build\n",
    "    if len(inference_main_build) == 0:\n",
    "        inference_main_build_geom = osm_main_build_geom\n",
    "        \n",
    "    # * Check for building expansion\n",
    "    # ** From OSM\n",
    "    union_main_build = inference_main_build_geom.union(osm_main_build_geom)\n",
    "    diff_main_build = compute_largest_protruding_poly(union_main_build, osm_main_build_geom)\n",
    "\n",
    "    parcel_main_build_geom = osm_main_build_geom\n",
    "    if (diff_main_build['area'] > MIN_ATTACHED_SIZE):\n",
    "        expansion_OSM_flag = True\n",
    "        osm_flag = False\n",
    "        parcel_main_build_geom = union_main_build\n",
    "        \n",
    "    # ** From 2016\n",
    "    expansion_2016_flag = None\n",
    "    if inference_main_build_geom_2016 is not None:\n",
    "        expansion_2016_flag = False\n",
    "        union_main_build = inference_main_build_geom.union(inference_main_build_geom_2016)\n",
    "        diff_20_16 = compute_largest_protruding_poly(union_main_build, inference_main_build_geom_2016)\n",
    "\n",
    "        if diff_20_16['area'] > MIN_ATTACHED_SIZE_2020_2016_DIFF:\n",
    "            expansion_2016_flag = True\n",
    "\n",
    "    # Generate main building gpd and append to parcel buildlings\n",
    "    parcel_main_build = gpd.GeoDataFrame(geometry=[parcel_main_build_geom], crs='EPSG:4326')\n",
    "    parcel_main_build['main_building_flag'] = True\n",
    "    parcel_main_build['expansion_OSM_flag'] = expansion_OSM_flag\n",
    "    parcel_main_build['expansion_2016_flag'] = expansion_2016_flag\n",
    "    parcel_main_build['OSM_flag'] = osm_flag\n",
    "    parcel_buildings = pd.concat([parcel_buildings, parcel_main_build[gpd_cols]])\n",
    "\n",
    "    # ii. Match small buildings\n",
    "    osm_buildings_parcel_small = osm_buildings_parcel.sort_values(\n",
    "        'area', ascending=False).iloc[1:].copy()\n",
    "    inferred_buildings_2020_parcel_small = inferred_buildings_2020_parcel.sjoin(\n",
    "        inference_main_build[['GEOID_left', 'geometry']], how='left', predicate='intersects')\n",
    "    inferred_buildings_2020_parcel_small = inferred_buildings_2020_parcel_small.loc[\n",
    "        inferred_buildings_2020_parcel_small['index_right'].isna()]\n",
    "    inferred_buildings_2020_parcel_small.drop('index_right', axis=1, inplace=True)\n",
    "\n",
    "    parcel_small_build = match_small_buildings(\n",
    "        inferred_buildings_2020_parcel_small, osm_buildings_parcel_small, gpd_cols)\n",
    "\n",
    "    parcel_buildings = pd.concat([parcel_buildings, parcel_small_build[gpd_cols]])\n",
    "    return parcel_buildings[gpd_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cca2908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_largest_protruding_poly(union_build, base_build):\n",
    "    \"\"\"\n",
    "    Note we care about concentrated building\n",
    "    # expansions along a single wall and not general changes in building footprint due to noisy\n",
    "    # inferences so we isolate the largest protruding polygon\n",
    "    \"\"\"\n",
    "    diff_main_build = gpd.GeoSeries(union_build.difference(base_build), crs='EPSG:4326')\n",
    "    diff_main_build = diff_main_build.explode(ignore_index=True, index_parts=False)\n",
    "    \n",
    "    diff_main_build = gpd.GeoDataFrame(geometry=diff_main_build, crs='EPSG:4326')\n",
    "    diff_main_build['area'] = diff_main_build.to_crs('EPSG:26910').area\n",
    "    diff_main_build = diff_main_build.sort_values('area', ascending=False).iloc[0]\n",
    "    return diff_main_build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96003202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_small_buildings(inferred, osm, gpd_cols):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Note: we want to default to using OSM unless there are small buildings not \n",
    "    # captured by OSM\n",
    "\n",
    "    if len(osm) == 0 and len(inferred) == 0:\n",
    "        return gpd.GeoDataFrame(geometry=[], columns=gpd_cols)\n",
    "\n",
    "    if (len(osm) == 0 and len(inferred) > 0) or (len(osm) > 0 and len(inferred) == 0):\n",
    "        parcel_small_build = osm.copy() if len(osm) > 0 else inferred.copy()\n",
    "        parcel_small_build['main_building_flag'] = False\n",
    "        parcel_small_build['OSM_flag'] = True if len(osm) > 0 else False\n",
    "        parcel_small_build['expansion_OSM_flag'] = False\n",
    "        parcel_small_build['expansion_2016_flag'] = False\n",
    "        return parcel_small_build[gpd_cols]\n",
    "\n",
    "    # Default to OSM\n",
    "    parcel_small_build = osm.copy()\n",
    "    parcel_small_build['main_building_flag'] = False\n",
    "    parcel_small_build['OSM_flag'] = True\n",
    "    parcel_small_build['expansion_OSM_flag'] = False\n",
    "    parcel_small_build['expansion_2016_flag'] = False\n",
    "\n",
    "    # Matching\n",
    "    inferred_match = inferred.sjoin(osm, predicate='intersects', how='left')\n",
    "\n",
    "    # Keep only isolated inferences not captured in OSM\n",
    "    inferred_match = inferred_match.loc[inferred_match['index_right'].isna()]\n",
    "    inferred_match = inferred_match[[\n",
    "      'GEOID_left', 'area_left', 'small_left', 'large_left', 'geometry']]\n",
    "    inferred_match.rename(\n",
    "      columns={c: c.replace('_left', '') for c in inferred_match.columns}, \n",
    "      inplace=True)\n",
    "    inferred_match['main_building_flag'] = False\n",
    "    inferred_match['OSM_flag'] = False\n",
    "    inferred_match['expansion_2016_flag'] = False\n",
    "    inferred_match['expansion_OSM_flag'] = False\n",
    "\n",
    "    parcel_small_build = pd.concat([parcel_small_build, inferred_match[gpd_cols]])\n",
    "    return parcel_small_build[gpd_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726f07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_permit_data(parcel_apn, permits_parcel, parcel_buildings):\n",
    "    # filter by parcel_buildings in this first pass\n",
    "    \"\"\"\n",
    "    We will only consider non-main buildings OR main buildings with a detected expansion from OSM or 2016.\n",
    "    \n",
    "    For each parcel, we will:\n",
    "    1. Filter for parcels that are clearly not SFRs (has >5 buildings)\n",
    "    \n",
    "    There are three types of classifications:\n",
    "    1. Permitted (building/activity matches to a permit)\n",
    "        - If expansion, permit needs to be issued between 2015-2020\n",
    "        - If small building, \n",
    "    2. Unpermitted (building/activity doesn't match reasonably to a permit)\n",
    "    \"\"\"\n",
    "    if parcel_buildings is not None:\n",
    "        if len(parcel_buildings) <= 5:\n",
    "            # then consider\n",
    "            parcel_buildings = parcel_buildings[(parcel_buildings['main_building_flag'] == False) | \\\n",
    "                                                ((parcel_buildings['main_building_flag']) & \\\n",
    "                                                 ((parcel_buildings['expansion_OSM_flag']) | \\\n",
    "                                                (parcel_buildings['expansion_2016_flag'])))]\n",
    "            if not parcel_buildings.empty:\n",
    "                # then start to do matching\n",
    "                if permits_parcel is not None and len(permits_parcel) > 0:\n",
    "                    ## ------ MAIN DRIVER HERE ------\n",
    "                    output_df = gpd.GeoDataFrame(columns=['apn'] + list(parcel_buildings.columns) + ['verdict', 'permit_id', 'certainty'])\n",
    "                    permit_nomatch_df = pd.DataFrame(columns=permits_parcel.columns)\n",
    "                    \n",
    "                    # then there is a permit matching in that parcel\n",
    "                    small_building = parcel_buildings[parcel_buildings['main_building_flag'] == False].reset_index(drop=True)\n",
    "                    expansion = parcel_buildings[(parcel_buildings['main_building_flag']) & \\\n",
    "                                                 ((parcel_buildings['expansion_OSM_flag']) | \\\n",
    "                                                (parcel_buildings['expansion_2016_flag']))].reset_index(drop=True)\n",
    "                    \n",
    "                    \n",
    "                    if not expansion.empty:\n",
    "                        assert len(expansion) == 1\n",
    "                        \n",
    "                        \n",
    "                    for idx, row in permits_parcel.iterrows():\n",
    "                        if row['WORKDESC'] == 'Additions/Alterations' and row['year'] <= 2020 and row['year'] >= 2015 \\\n",
    "                        and row['PERMITVALUE'] > 0 and row['SQUAREFOOT'] > 0:\n",
    "                            if not expansion.empty:\n",
    "                                output_df.loc[len(output_df)] = [parcel_apn] + expansion.loc[0].tolist() + ['permitted', row['OBJECTID_left'], 3]\n",
    "                                expansion.drop(0, inplace=True)\n",
    "                            else:\n",
    "                                permit_nomatch_df.loc[len(permit_nomatch_df)] = row.tolist()\n",
    "                        elif row['WORKDESC'] == 'Additions/Alterations' and row['year'] <= 2020 and row['year'] >= 2015 \\\n",
    "                        and row['PERMITVALUE'] > 0:\n",
    "                            if not expansion.empty:\n",
    "                                output_df.loc[len(output_df)] = [parcel_apn] + expansion.loc[0].tolist() + ['permitted', row['OBJECTID_left'], 2]\n",
    "                                expansion.drop(0, inplace=True)\n",
    "                            else:\n",
    "                                permit_nomatch_df.loc[len(permit_nomatch_df)] = row.tolist()\n",
    "                        elif row['WORKDESC'] == 'Additions/Alterations' and row['year'] <= 2020 and row['year'] >= 2015:\n",
    "                            if not expansion.empty:\n",
    "                                output_df.loc[len(output_df)] = [parcel_apn] + expansion.loc[0].tolist() + ['permitted', row['OBJECTID_left'], 1]\n",
    "                                expansion.drop(0, inplace=True)\n",
    "                            else:\n",
    "                                permit_nomatch_df.loc[len(permit_nomatch_df)] = row.tolist()\n",
    "                        elif (row['WORKDESC'] == 'New Construction' or row['WORKDESC'] == 'Additions/Alterations') and row['DWELLINGUNIT'] > 0 and \\\n",
    "                        row['PERMITVALUE'] > 0 and row['SQUAREFOOT'] > 0:\n",
    "                            if not small_building.empty:\n",
    "                                output_df.loc[len(output_df)] = [parcel_apn] + small_building.loc[0].tolist() + ['permitted', row['OBJECTID_left'], 3]\n",
    "                                small_building = small_building.drop(0).reset_index(drop=True)\n",
    "                            elif not expansion.empty and row['year'] <= 2020 and row['year'] >= 2015:\n",
    "                                output_df.loc[len(output_df)] = [parcel_apn] + expansion.loc[0].tolist() + ['permitted', row['OBJECTID_left'], 3]\n",
    "                                expansion.drop(0, inplace=True)\n",
    "                            else:\n",
    "                                permit_nomatch_df.loc[len(permit_nomatch_df)] = row.tolist()\n",
    "                        elif (row['WORKDESC'] == 'New Construction' or row['WORKDESC'] == 'Additions/Alterations') and row['PERMITVALUE'] > 0 and row['SQUAREFOOT'] > 0:\n",
    "                            if not small_building.empty:\n",
    "                                output_df.loc[len(output_df)] = [parcel_apn] + small_building.loc[0].tolist() + ['permitted', row['OBJECTID_left'], 3]\n",
    "                                small_building = small_building.drop(0).reset_index(drop=True)\n",
    "                            elif not expansion.empty and row['year'] <= 2020 and row['year'] >= 2015:\n",
    "                                output_df.loc[len(output_df)] = [parcel_apn] + expansion.loc[0].tolist() + ['permitted', row['OBJECTID_left'], 2]\n",
    "                                expansion.drop(0, inplace=True)\n",
    "                            else:\n",
    "                                permit_nomatch_df.loc[len(permit_nomatch_df)] = row.tolist()\n",
    "                        elif (row['WORKDESC'] == 'New Construction' or row['WORKDESC'] == 'Additions/Alterations'):\n",
    "                            if not small_building.empty:\n",
    "                                output_df.loc[len(output_df)] = [parcel_apn] + small_building.loc[0].tolist() + ['permitted', row['OBJECTID_left'], 3]\n",
    "                                small_building = small_building.drop(0).reset_index(drop=True)\n",
    "                            elif not expansion.empty and row['year'] <= 2020 and row['year'] >= 2015:\n",
    "                                output_df.loc[len(output_df)] = [parcel_apn] + expansion.loc[0].tolist() + ['permitted', row['OBJECTID_left'], 1]\n",
    "                                expansion.drop(0, inplace=True)\n",
    "                            else:\n",
    "                                permit_nomatch_df.loc[len(permit_nomatch_df)] = row.tolist()\n",
    "                            # then try to find the expansion\n",
    "                        else:\n",
    "                            print(row[['WORKDESC', 'SUBDESC', 'DWELLINGUNIT', 'PERMITVALUE', 'SQUAREFOOT', 'year']])\n",
    "                            # add to unmatched permits -- probably permits never went through or FN from model\n",
    "                    \n",
    "                    # rest is unpermitted\n",
    "                    if not small_building.empty:\n",
    "                        small_building['verdict'] = 'unpermitted'\n",
    "                        small_building['apn'] = parcel_apn\n",
    "                        output_df = pd.concat([output_df, small_building])\n",
    "                        \n",
    "                    if not expansion.empty:\n",
    "                        expansion['verdict'] = 'unpermitted'\n",
    "                        expansion['apn'] = parcel_apn\n",
    "                        output_df = pd.concat([output_df, expansion])\n",
    "                        \n",
    "                    return output_df, permit_nomatch_df\n",
    "#                     if not expansion.empty:\n",
    "#                         print(expansion)\n",
    "#                         print(permits_parcel[['WORKDESC', 'SUBDESC', 'DWELLINGUNIT', 'PERMITVALUE', 'SQUAREFOOT', 'FOLDERNUM']])\n",
    "                        \n",
    "#                     if not small_building.empty:\n",
    "#                         print(small_building)\n",
    "#                         print(permits_parcel[['WORKDESC', 'SUBDESC', 'DWELLINGUNIT', 'PERMITVALUE', 'SQUAREFOOT', 'FOLDERNUM']])\n",
    "                    \n",
    "                        \n",
    "                else:\n",
    "                    # return all the filtered parcel_buildings, with the caveat that we're highly overestimating\n",
    "                    parcel_buildings['verdict'] = 'unpermitted'\n",
    "                    parcel_buildings['apn'] = parcel_apn\n",
    "                    return parcel_buildings, None\n",
    "            else:\n",
    "                # return nothing since we can't consider any of the buildings (at least not rn)\n",
    "#                 if permits_parcel is not None and len(permits_parcel) > 0:\n",
    "#                     return None, permits_parcel\n",
    "#                 else:\n",
    "#                     return None, None\n",
    "                return None, None\n",
    "        else:\n",
    "            # return nothing since we don't want to consider this parcel\n",
    "            return None, None\n",
    "    \n",
    "#     if len(permits_parcel) > 0:\n",
    "#         print(permits_parcel[['WORKDESC', 'SUBDESC', 'DWELLINGUNIT', 'PERMITVALUE', 'SQUAREFOOT', 'FOLDERNUM']])\n",
    "#         if parcel_buildings is not None:\n",
    "#             print(parcel_buildings)\n",
    "#         else:\n",
    "#             print(0)\n",
    "#         pass\n",
    "#     else:\n",
    "#         return parcel_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0132d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c68d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7847af2a",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2438af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('shortlist.csv'):\n",
    "    shortlist = pd.read_csv('shortlist.csv')\n",
    "else:\n",
    "    shortlist = pd.DataFrame(columns=['apn', 'main_building_flag', 'OSM_flag', \n",
    "                                      'expansion_OSM_flag', 'expansion_2016_flag', \n",
    "                                      'geometry', 'verdict', 'permit_id', 'certainty'])\n",
    "    \n",
    "if os.path.exists('permit_nomatch.csv'):\n",
    "    permit_nomatch = pd.read_csv('permit_nomatch.csv')\n",
    "else:\n",
    "    permit_nomatch = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c712a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each parcel\n",
    "parcel_apns = sj_parcels_res['APN'].unique()\n",
    "idx = 0\n",
    "for parcel_apn in tqdm(parcel_apns):\n",
    "    # Run the condition below if you want to filter only on permits that match to a parcel\n",
    "#     if not sj_parcel_permit[sj_parcel_permit['APN_parcel'] == parcel_apn].empty:\n",
    "    shortlist_parcel, permit_nomatch_df = match_parcel(parcel_apn)\n",
    "    if shortlist_parcel is not None and len(shortlist_parcel) > 0:\n",
    "        shortlist = pd.concat([shortlist, shortlist_parcel])\n",
    "    if permit_nomatch_df is not None and len(permit_nomatch_df) > 0:\n",
    "        permit_nomatch = pd.concat([permit_nomatch, permit_nomatch_df]) \n",
    "    idx += 1\n",
    "    if idx % 100 == 0:\n",
    "        shortlist.to_csv('shortlist.csv', index=False)\n",
    "        permit_nomatch.to_csv('permit_nomatch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13aeb2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-6bc5c298663f>:17: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df_out['iou'] = df_out['geometry'].intersection(parcel_bounds).area/df_out['geometry'].area\n",
      "<ipython-input-6-6bc5c298663f>:17: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df_out['iou'] = df_out['geometry'].intersection(parcel_bounds).area/df_out['geometry'].area\n",
      "<ipython-input-6-6bc5c298663f>:17: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df_out['iou'] = df_out['geometry'].intersection(parcel_bounds).area/df_out['geometry'].area\n",
      "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:9190: FutureWarning: Passing 'suffixes' which cause duplicate columns {'GEOID_left'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  return merge(\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "parcel_apn='48114037'\n",
    "inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel, permits_parcel = parcel_level_data(parcel_apn, sj_parcels_res, sj_parcel_permit)\n",
    "parcel_buildings = process_OSM_data(\n",
    "    inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458e7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Sort shortlists\n",
    "# TO DO\n",
    "# Risk levels:\n",
    "# highest risk, no permitted additions of any kind, and you detect detached\n",
    "# no permitted additions of any kind, and you detect attached\n",
    "# permitted detached ADU, you detect more than one detached\n",
    "# permitted detached ADU, you detect attached and detached\n",
    "# permitted attached ADU, you detect attached and detached\n",
    "# permitted attached ADU, you detect a detached (or vice versa)\n",
    "# permitted attached ADU and detached ADU, you detect anything unpermitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341cd72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
