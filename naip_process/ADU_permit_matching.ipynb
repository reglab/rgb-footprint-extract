{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5af55ad",
   "metadata": {},
   "source": [
    "# Identify permitted and potentially unpermitted attached and detached units in San Jose (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc420f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae725b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "OAK_FP = '/oak/stanford/groups/deho/building_compliance/'\n",
    "INPUT_FP = os.path.join(OAK_FP, 'outputs', 'Permit-Matching')\n",
    "SJ_RES_PARCELS_FP = os.path.join(INPUT_FP, 'inputs', 'san_jose_parcels_res.geojson')\n",
    "ZONING_FP = os.path.join(OAK_FP, 'san_jose_suppl', 'san_jose_Zoning_Districts.geojson')\n",
    "BUILD_FP = os.path.join(OAK_FP, 'outputs', 'cbg-inference-{}', 'inference_building_processed')\n",
    "OSM_FP = os.path.join(OAK_FP, 'outputs', 'cbg-inference-2020', 'osm_building_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd200028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# * Residential parcels\n",
    "sj_parcels_res = gpd.read_file(SJ_RES_PARCELS_FP)\n",
    "sj_parcels_res = sj_parcels_res[sj_parcels_res['APN'].notna()]\n",
    "\n",
    "# * Building permits\n",
    "bldg_active = gpd.read_file(os.path.join(INPUT_FP, 'inputs', 'permits', 'bldg_active.geojson'))\n",
    "bldg_recent = gpd.read_file(os.path.join(INPUT_FP, 'inputs','permits', 'bldg_recent.geojson'))\n",
    "bldg_expired = gpd.read_file(os.path.join(INPUT_FP, 'inputs', 'permits', 'bldg_expired.geojson'))\n",
    "\n",
    "# * Zoning\n",
    "sj_zoning = gpd.read_file(ZONING_FP)\n",
    "sj_residential = sj_zoning[(sj_zoning['ZONING'].str.contains('R-1')) | (sj_zoning['ZONING'].str.contains('R-2')) |\\\n",
    "         ((sj_zoning['ZONING'].str.contains('R-M')) & (sj_zoning['ZONING'] != 'R-MH'))]\n",
    "\n",
    "# * parcel+permit\n",
    "sj_parcel_permit = pd.read_csv(os.path.join(INPUT_FP, 'outputs', 'parcel_permit_found.csv'))\n",
    "sj_permit_noparcel = pd.read_csv(os.path.join(INPUT_FP, 'outputs', 'parcel_permit_notfound.csv'))\n",
    "sj_parcel_permit['geometry_parcel'] = gpd.GeoSeries.from_wkt(sj_parcel_permit['geometry_parcel'])\n",
    "sj_parcel_permit['geometry_permit'] = gpd.GeoSeries.from_wkt(sj_parcel_permit['geometry_permit'])\n",
    "sj_permit_noparcel['geometry'] = gpd.GeoSeries.from_wkt(sj_permit_noparcel['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d495de",
   "metadata": {},
   "source": [
    "Handle active permits differently than expired permits\n",
    "- Expired permits barely report dwelling units and square footage\n",
    "- Should we filter really finely like we do for active permits, or filter for just work description as we do for expired permits to catch ALL the construction permits we can find? I worry that some of the buildings we infer will be under non-SFR permits\n",
    "\n",
    "Keep this block of code in case we want to filter more specifically for possible dwelling units, but we will work with the more relaxed conditions to get more possible permits to compare to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9078811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter permits\n",
    "cols = list(bldg_active.columns) + ['permit_status']\n",
    "permits = gpd.GeoDataFrame(columns=cols)\n",
    "for i, status in zip([bldg_active, bldg_recent, bldg_expired], ['active', 'recent', 'expired']):\n",
    "    i['permit_status'] = status\n",
    "    permits = pd.concat([permits, i[i['WORKDESC'].isin(['New Construction', 'Additions/Alterations'])]])\n",
    "permits = permits.reset_index(drop=True)\n",
    "\n",
    "permits.crs = \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a041a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e679cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_parcel(parcel_apn):\n",
    "    # Obtain parcel-level data\n",
    "    parcel_inputs = parcel_level_data(\n",
    "      parcel_apn, sj_parcels_res. sj_parcel_permit)\n",
    "    inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel, permits_parcel = parcel_inputs\n",
    "\n",
    "    # Incorporate OSM data\n",
    "    parcel_buildings = process_OSM_data(\n",
    "      inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel)\n",
    "\n",
    "    # Incorporate permit data\n",
    "    parcel_buildings = process_permit_data(permits_parcel, parcel_buildings)\n",
    "\n",
    "    return parcel_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39cc119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcel_level_data(parcel_apn, sj_parcels_res, sj_parcel_permit):\n",
    "    parcel_bounds = sj_parcels_res[sj_parcels_res['APN'] == parcel_apn]\n",
    "\n",
    "    # clip inferred buildings and osm buildings\n",
    "    # i don't think clip is a good idea since it truncates the inferences according to the mask\n",
    "    # inferred_buildings_2020_parcel = gpd.clip(building_inference_2020, parcel_bounds)\n",
    "\n",
    "    # def mask_buildings(df, parcel_bounds):\n",
    "    #   df_out = df.sjoin(parcel_bounds[['geometry','geom']])\n",
    "    #   # print(df_out)\n",
    "    #   df_out['iou'] = df_out['geometry'].intersection(df_out['geom']).area/df_out['geom'].area\n",
    "    #   df_out = df_out[df_out['iou'] > 0.7]\n",
    "    #   return df_out\n",
    "\n",
    "    def mask_buildings1(parcel_bounds, fp):\n",
    "        df_out = gpd.read_file(fp, mask=parcel_bounds)\n",
    "        df_out['iou'] = df_out['geometry'].intersection(parcel_bounds).area/df_out['geometry'].area\n",
    "        df_out = df_out[df_out['iou'] > 0.7]\n",
    "        if df_out.empty:\n",
    "            return None\n",
    "        else:\n",
    "            return df_out\n",
    "\n",
    "    inferred_buildings_2020_parcel = mask_buildings1(parcel_bounds['geometry'].values[0], BUILD_FP.format('2020'))\n",
    "    inferred_buildings_2016_parcel = mask_buildings1(parcel_bounds['geometry'].values[0], BUILD_FP.format('2016'))\n",
    "    osm_buildings_parcel = mask_buildings1(parcel_bounds['geometry'].values[0], OSM_FP)\n",
    "\n",
    "    permits_parcel = sj_parcel_permit[sj_parcel_permit['APN_parcel'] == parcel_apn]\n",
    "    if permits_parcel.empty:\n",
    "        permits_parcels = None\n",
    "\n",
    "    return inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel, permits_parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "214e90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_ATTACHED_SIZE = 20\n",
    "MIN_ATTACHED_SIZE_2020_2016_DIFF = 30\n",
    "\n",
    "def process_OSM_data(inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel):\n",
    "    # Returns a gpd.GeoDataFrame with the following columns:\n",
    "    #   - GEOID, area, small, large\n",
    "    #   - flags: OSM_flag, expansion_flag, main_building_flag\n",
    "    #   - building geometry\n",
    "    gpd_cols = ['main_building_flag', 'OSM_flag', 'expansion_flag', 'geometry']\n",
    "    parcel_buildings = gpd.GeoDataFrame(geometry=[], columns=gpd_cols)\n",
    "    \n",
    "    # Drop OSM index_left column\n",
    "    if osm_buildings_parcel is not None and 'index_left' in osm_buildings_parcel.columns:\n",
    "        osm_buildings_parcel.drop('index_left', axis=1, inplace=True)\n",
    "\n",
    "    # No inference nor OSM data\n",
    "    if inferred_buildings_2020_parcel is None and osm_buildings_parcel is None:\n",
    "        return parcel_buildings\n",
    "\n",
    "    # No inference but OSM data: then we fully rely on OSM data\n",
    "    if inferred_buildings_2020_parcel is None and (osm_buildings_parcel is not None and len(osm_buildings_parcel) > 0):\n",
    "        parcel_buildings = osm_buildings_parcel.copy()\n",
    "        parcel_buildings = parcel_buildings.sort_values('area', ascending=False)\n",
    "        parcel_buildings['main_building_flag'] = parcel_buildings.apply(\n",
    "            lambda row: True if row.name == 0 else False, axis=1)\n",
    "        parcel_buildings['OSM_flag'] = True\n",
    "        parcel_buildings['expansion_flag'] = False\n",
    "        return parcel_buildings[gpd_cols]\n",
    "    \n",
    "    # Inference and no OSM data\n",
    "    if len(inferred_buildings_2020_parcel) > 0 and osm_buildings_parcel is None:\n",
    "\n",
    "        # i. Identify main building\n",
    "        inferred_buildings_2020_parcel = inferred_buildings_2020_parcel.sort_values(\n",
    "            'area', ascending=False)\n",
    "        inference_main_build = inferred_buildings_2020_parcel.iloc[[0]]\n",
    "        inference_main_build_geom = inference_main_build['geometry'].iloc[0]\n",
    "        expansion_flag = False\n",
    "\n",
    "        parcel_buildings = inference_main_build.copy()\n",
    "\n",
    "        # ii. Compare to 2016 footprint\n",
    "        if len(inferred_buildings_2016_parcel) > 0:\n",
    "            # Identify 2016 main building\n",
    "            inferred_buildings_2016_parcel = inferred_buildings_2016_parcel.sort_values(\n",
    "                'area', ascending=False)\n",
    "            inference_main_build_2016 = inferred_buildings_2016_parcel.iloc[0]\n",
    "            inference_main_build_geom_2016 = inference_main_build_2016['geometry']\n",
    "\n",
    "          # Compare\n",
    "            union_main_build = inference_main_build_geom.union(inference_main_build_geom_2016)\n",
    "            diff_20_16 = compute_largest_protruding_poly(union_main_build, inference_main_build_geom_2016)\n",
    "\n",
    "            if diff_20_16['area'] > MIN_ATTACHED_SIZE_2020_2016_DIFF:\n",
    "                parcel_buildings = inference_main_build_2016.copy()\n",
    "                expansion_flag = True\n",
    "\n",
    "        parcel_buildings['expansion_flag'] = expansion_flag\n",
    "        parcel_buildings['main_building_flag'] = True\n",
    "        parcel_buildings['OSM_flag'] = False\n",
    "        parcel_buildings = parcel_buildings[gpd_cols]\n",
    "\n",
    "        # iii. Add inferred small buildings \n",
    "        inferred_small = inferred_buildings_2020_parcel.iloc[1:].copy()\n",
    "        inferred_small['expansion_flag'] = False\n",
    "        inferred_small['OSM_flag'] = False\n",
    "        inferred_small['main_building_flag'] = False\n",
    "        parcel_buildings = pd.concat([parcel_buildings, inferred_small[gpd_cols]])\n",
    "\n",
    "        return parcel_buildings[gpd_cols]\n",
    "\n",
    "    # Inference and OSM data\n",
    "    if len(inferred_buildings_2020_parcel) > 0 and len(osm_buildings_parcel) > 0:\n",
    "        \n",
    "        parcel_buildings = gpd.GeoDataFrame(geometry=[])\n",
    "\n",
    "        # i. Identify main building(s) in OSM and inferences\n",
    "        osm_main_build = osm_buildings_parcel.sort_values('area', ascending=False).iloc[[0]]\n",
    "        osm_main_build_geom = osm_main_build['geometry'].iloc[0]\n",
    "        \n",
    "        inference_main_build = inferred_buildings_2020_parcel.sjoin(\n",
    "            osm_main_build, how='left', predicate='intersects')\n",
    "        inference_main_build = inference_main_build.loc[~inference_main_build['index_right'].isna()]\n",
    "        inference_main_build_geom = inference_main_build.geometry.unary_union\n",
    "        inference_main_build.drop('index_right', axis=1, inplace=True)\n",
    "        \n",
    "        # * Check for building expansion. Note we care about concentrated building\n",
    "        # expansions along a single wall and not general changes in building footprint due to noisy\n",
    "        # inferences so we isolate the largest protruding polygon\n",
    "        union_main_build = inference_main_build_geom.union(osm_main_build_geom)\n",
    "        diff_main_build = compute_largest_protruding_poly(union_main_build, osm_main_build_geom)\n",
    "        \n",
    "        expansion_flag = False\n",
    "        osm_flag = True\n",
    "        parcel_main_build_geom = osm_main_build_geom\n",
    "        if (diff_main_build['area'] > MIN_ATTACHED_SIZE):\n",
    "            expansion_flag = True\n",
    "            osm_flag = False\n",
    "            parcel_main_build_geom = union_main_build\n",
    "        \n",
    "        # Generate main building gpd and append to parcel buildlings\n",
    "        parcel_main_build = gpd.GeoDataFrame(geometry=[parcel_main_build_geom], crs='EPSG:4326')\n",
    "        parcel_main_build['main_building_flag'] = True\n",
    "        parcel_main_build['expansion_flag'] = expansion_flag\n",
    "        parcel_main_build['OSM_flag'] = osm_flag\n",
    "        parcel_buildings = pd.concat([parcel_buildings, parcel_main_build[gpd_cols]])\n",
    "        \n",
    "        # ii. Match small buildings\n",
    "        osm_buildings_parcel_small = osm_buildings_parcel.sort_values(\n",
    "            'area', ascending=False).iloc[1:].copy()\n",
    "        inferred_buildings_2020_parcel_small = inferred_buildings_2020_parcel.sjoin(\n",
    "            inference_main_build[['GEOID_left', 'geometry']], how='left', predicate='intersects')\n",
    "        inferred_buildings_2020_parcel_small = inferred_buildings_2020_parcel_small.loc[\n",
    "            inferred_buildings_2020_parcel_small['index_right'].isna()]\n",
    "        inferred_buildings_2020_parcel_small.drop('index_right', axis=1, inplace=True)\n",
    "        \n",
    "        parcel_small_build = match_small_buildings(\n",
    "            inferred_buildings_2020_parcel_small, osm_buildings_parcel_small, gpd_cols)\n",
    "\n",
    "        parcel_buildings = pd.concat([parcel_buildings, parcel_small_build[gpd_cols]])\n",
    "        return parcel_buildings[gpd_cols]\n",
    "\n",
    "\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cca2908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_largest_protruding_poly(union_build, base_build):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    diff_main_build = gpd.GeoSeries(union_build.difference(base_build), crs='EPSG:4326')\n",
    "    diff_main_build = diff_main_build.explode(ignore_index=True, index_parts=False)\n",
    "    \n",
    "    diff_main_build = gpd.GeoDataFrame(geometry=diff_main_build, crs='EPSG:4326')\n",
    "    diff_main_build['area'] = diff_main_build.to_crs('EPSG:26910').area\n",
    "    diff_main_build = diff_main_build.sort_values('area', ascending=False).iloc[0]\n",
    "    return diff_main_build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96003202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_small_buildings(inferred, osm, gpd_cols):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Note: we want to default to using OSM unless there are small buildings not \n",
    "    # captured by OSM\n",
    "\n",
    "    if len(osm) == 0 and len(inferred) == 0:\n",
    "        return gpd.GeoDataFrame(geometry=[], columns=gpd_cols)\n",
    "\n",
    "    if (len(osm) == 0 and len(inferred) > 0) or (len(osm) > 0 and len(inferred) == 0):\n",
    "        parcel_small_build = osm.copy() if len(osm) > 0 else inferred.copy()\n",
    "        parcel_small_build['main_building_flag'] = False\n",
    "        parcel_small_build['OSM_flag'] = True if len(osm) > 0 else False\n",
    "        parcel_small_build['expansion_flag'] = False\n",
    "        return parcel_small_build[gpd_cols]\n",
    "\n",
    "    # Default to OSM\n",
    "    parcel_small_build = osm.copy()\n",
    "    parcel_small_build['main_building_flag'] = False\n",
    "    parcel_small_build['OSM_flag'] = True\n",
    "    parcel_small_build['expansion_flag'] = False\n",
    "\n",
    "    # Matching\n",
    "    inferred_match = inferred.sjoin(osm, predicate='intersects', how='left')\n",
    "\n",
    "    # Keep only isolated inferences not captured in OSM\n",
    "    inferred_match = inferred_match.loc[inferred_match['index_right'].isna()]\n",
    "    inferred_match = inferred_match[[\n",
    "      'GEOID_left', 'area_left', 'small_left', 'large_left', 'geometry']]\n",
    "    inferred_match.rename(\n",
    "      columns={c: c.replace('_left', '') for c in inferred_match.columns}, \n",
    "      inplace=True)\n",
    "    inferred_match['main_building_flag'] = False\n",
    "    inferred_match['OSM_flag'] = False\n",
    "    inferred_match['expansion_flag'] = False\n",
    "\n",
    "    parcel_small_build = pd.concat([parcel_small_build, inferred_match[gpd_cols]])\n",
    "    return parcel_small_build[gpd_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726f07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_permit_data(permits_parcel, parcel_buildings):\n",
    "    if len(permits_parcel) > 0:\n",
    "        # TO DO\n",
    "        pass\n",
    "    else:\n",
    "        return parcel_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0132d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c68d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7847af2a",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlist = gpd.GeoDataFrame()\n",
    "\n",
    "# Loop over each parcel\n",
    "parcel_apns = sj_parcels_res['APN'].unique()\n",
    "for parcel_apn in parcel_apns:\n",
    "    shortlist_parcel = match_parcel(parcel_apn)\n",
    "\n",
    "    # Append to shortlist\n",
    "    if len(shortlist_parcel) > 0:\n",
    "      shortlist = pd.concat([shortlist, shortlist_parcel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13aeb2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-6bc5c298663f>:17: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df_out['iou'] = df_out['geometry'].intersection(parcel_bounds).area/df_out['geometry'].area\n",
      "<ipython-input-6-6bc5c298663f>:17: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df_out['iou'] = df_out['geometry'].intersection(parcel_bounds).area/df_out['geometry'].area\n",
      "<ipython-input-6-6bc5c298663f>:17: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df_out['iou'] = df_out['geometry'].intersection(parcel_bounds).area/df_out['geometry'].area\n",
      "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:9190: FutureWarning: Passing 'suffixes' which cause duplicate columns {'GEOID_left'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  return merge(\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "parcel_apn='48114037'\n",
    "inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel, permits_parcel = parcel_level_data(parcel_apn, sj_parcels_res, sj_parcel_permit)\n",
    "parcel_buildings = process_OSM_data(\n",
    "    inferred_buildings_2020_parcel, inferred_buildings_2016_parcel, osm_buildings_parcel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458e7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Sort shortlists\n",
    "# TO DO\n",
    "# Risk levels:\n",
    "# highest risk, no permitted additions of any kind, and you detect detached\n",
    "# no permitted additions of any kind, and you detect attached\n",
    "# permitted detached ADU, you detect more than one detached\n",
    "# permitted detached ADU, you detect attached and detached\n",
    "# permitted attached ADU, you detect attached and detached\n",
    "# permitted attached ADU, you detect a detached (or vice versa)\n",
    "# permitted attached ADU and detached ADU, you detect anything unpermitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341cd72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
